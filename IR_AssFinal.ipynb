{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T14:10:33.090195Z","iopub.status.busy":"2024-03-13T14:10:33.089811Z","iopub.status.idle":"2024-03-13T14:10:43.329496Z","shell.execute_reply":"2024-03-13T14:10:43.328263Z","shell.execute_reply.started":"2024-03-13T14:10:33.090167Z"},"trusted":true},"outputs":[],"source":["import  numpy as np\n","import  matplotlib.pyplot as plt\n","import cv2\n","import pandas as pd\n","import requests\n","import cv2\n","import torch\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","from sklearn.preprocessing import normalize\n","import pickle"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T14:10:43.332077Z","iopub.status.busy":"2024-03-13T14:10:43.331552Z","iopub.status.idle":"2024-03-13T14:10:44.943799Z","shell.execute_reply":"2024-03-13T14:10:44.942628Z","shell.execute_reply.started":"2024-03-13T14:10:43.332047Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["# Define the pre-trained ResNet model\n","resnet = models.resnet50(pretrained=True)\n","\n","# Remove the last layer\n","feature_extractor = torch.nn.Sequential(*(list(resnet.children())[:-1]))\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["\n","\n","# Load the dataset back\n","with open('data.pkl', 'rb') as f:\n","    loaded_data = pickle.load(f)\n","\n","    \n","\n","data=loaded_data\n","tfidf = pd.read_csv('tfidf.csv')\n","tfidf_df = pd.DataFrame(tfidf)\n","# normalise tfidf scores\n","normalized_tfidf = normalize(tfidf, axis=1, norm='l2')\n","# convert normalized tfidf scores to a dataframe\n","normalized_tfidf_df = pd.DataFrame(normalized_tfidf)\n","\n","\n","\n","imgSimilarity=pd.read_csv('image_similarity.csv')\n","image_similarity_M = pd.DataFrame(imgSimilarity)\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T14:10:45.010983Z","iopub.status.busy":"2024-03-13T14:10:45.010611Z","iopub.status.idle":"2024-03-13T14:10:45.158708Z","shell.execute_reply":"2024-03-13T14:10:45.157597Z","shell.execute_reply.started":"2024-03-13T14:10:45.010955Z"},"trusted":true},"outputs":[],"source":["\n","\n","def adjust_brightness_and_contrast(image, brightness=0, contrast=0):\n","        # Alpha controls contrast; Beta controls brightness.\n","        alpha = 1 + contrast / 127\n","        beta = brightness\n","        adjusted_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n","        return adjusted_image\n","\n","def preprocess(image_url):\n","    response = requests.get(image_url)\n","    image = cv2.imdecode(np.frombuffer(response.content, np.uint8), -1)\n","    if image is None:\n","        return None\n","    image_height, image_width = image.shape[:2]\n","    #border removal\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    _,thresh = cv2.threshold(gray,1,255,cv2.THRESH_BINARY)\n","    contours,hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n","    x,y,w,h = cv2.boundingRect(contours[0])\n","    image = image[y:y+h,x:x+w]\n","    image = cv2.resize(image, (80, 80))\n","\n","\n","    # Random flip\n","    flip_direction = np.random.choice([\"horizontal\", \"vertical\"])\n","    if flip_direction == \"horizontal\":\n","        image = cv2.flip(image, 1)  # 1: Flip horizontally\n","    elif flip_direction == \"vertical\":\n","        image = cv2.flip(image, 0)  # 0: Flip vertically\n","\n","    \n","\n","    #pixel normalisation\n","    def normalize_image(image):\n","        normalized_image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n","        return normalized_image\n","\n","    image = normalize_image(image)\n","    \n","\n","    #brightness and contrast adjustment\n","    def calculate_brightness_and_contrast(image):\n","        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","        mean, std_dev = cv2.meanStdDev(gray_image)\n","        return mean[0][0], std_dev[0][0]\n","\n","    \n","\n","    mean_brightness, std_dev_contrast = calculate_brightness_and_contrast(image)\n","\n","    # Set a threshold for deciding whether to adjust brightness and contrast\n","    brightness_threshold = 20  \n","    contrast_threshold = 10 \n","\n","    # Adjust brightness and contrast only if needed\n","    if mean_brightness < brightness_threshold or std_dev_contrast < contrast_threshold:\n","        brightness = 20  \n","        contrast = 20  \n","        adjusted_image = adjust_brightness_and_contrast(image, brightness=brightness, contrast=contrast)\n","    else:\n","        adjusted_image = image\n","\n","    return adjusted_image\n","\n","\n","\n","\n","\n","def extract_features(image):\n","    img = cv2.resize(image, (224, 224))\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    img_tensor = transforms.ToTensor()(img)\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    img_normalized = normalize(img_tensor)\n","    img_normalized = img_normalized.unsqueeze(0)\n","    with torch.no_grad():\n","        features = feature_extractor(img_normalized)\n","    features = features.view(features.size(0), -1)\n","    features = features.numpy()\n","    return features\n","\n","\n","\n","\n","def ImagecosineSim(image_id1, image_id2):\n","    features1 = imageTOvec(image_id1)\n","    features2 = imageTOvec(image_id2)\n","    similarity = np.dot(features1, features2.T)\n","    return similarity\n","\n","\n","\n","def imageTOvec(image_id):\n","    image_url = image_id\n","    # print(image_url)\n","    image = preprocess(image_url)\n","    if image is None:\n","        return None\n","    features = extract_features(image)\n","    return features"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.status.busy":"2024-03-13T14:15:03.083308Z","iopub.status.idle":"2024-03-13T14:15:03.083675Z","shell.execute_reply":"2024-03-13T14:15:03.083514Z","shell.execute_reply.started":"2024-03-13T14:15:03.083499Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["#  preprorcess revierw texts\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer as ps\n","\n","# Download the stopwords corpus if you haven't already\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","stop_words = set(stopwords.words('english'))\n","\n","def preprocess_review_text(review_text):\n","    # print(review_text)\n","    # print index of the reivew text\n","    review_text = str(review_text)\n","    review_text = review_text.lower()\n","    review_text = re.sub(r'[^\\w\\s]', '', review_text)\n","    # remove stop words\n","    review_text = ' '.join([word for word in review_text.split() if word not in stop_words])\n","    # do stemming\n","    review_text = ' '.join([ps().stem(word) for word in review_text.split()])\n","    return review_text\n","\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.status.busy":"2024-03-13T14:15:03.085619Z","iopub.status.idle":"2024-03-13T14:15:03.086021Z","shell.execute_reply":"2024-03-13T14:15:03.085854Z","shell.execute_reply.started":"2024-03-13T14:15:03.085838Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from collections import Counter\n","import math\n","\n","def tokenize(text):\n","    # Split text into tokens (words)\n","    return text.split()\n","\n","def calculate_tf(text):\n","    # Calculate term frequency (TF) for each word in the text\n","    tokens = tokenize(text)\n","    word_count = Counter(tokens)\n","    total_words = len(tokens)\n","    tf = {word: count / total_words for word, count in word_count.items()}\n","    return tf\n","\n","def calculate_idf(documents):\n","    # Calculate inverse document frequency (IDF) for each word\n","    total_documents = len(documents)\n","    all_words = set([word for document in documents for word in tokenize(document)])\n","    idf = {}\n","    for word in all_words:\n","        doc_count = sum([1 for document in documents if word in tokenize(document)])\n","        idf[word] = math.log10(total_documents / doc_count)\n","    return idf\n","\n","def calculate_tfidf(text, idf):\n","    # Calculate TF-IDF for each word in the text using precomputed IDF values\n","    tf = calculate_tf(text)\n","    tfidf = {word: tf[word] * idf[word] for word in tf}\n","    return tfidf\n","\n","\n"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.status.busy":"2024-03-13T14:15:03.089275Z","iopub.status.idle":"2024-03-13T14:15:03.089629Z","shell.execute_reply":"2024-03-13T14:15:03.089471Z","shell.execute_reply.started":"2024-03-13T14:15:03.089456Z"},"trusted":true},"outputs":[],"source":["\n","\n","def cosineSimText(text1, text2):\n","\n","    idf = calculate_idf([text1, text2])\n","    tfidf1 = calculate_tfidf(text1, idf)\n","    tfidf2 = calculate_tfidf(text2, idf)\n","\n","    # Calculate the dot product of tfidf1 and tfidf2\n","    dot_product = sum([tfidf1[word] * tfidf2[word] for word in tfidf1 if word in tfidf2])\n","\n","    # Calculate the magnitude of tfidf1 and tfidf2\n","    magnitude1 = math.sqrt(sum([tfidf1[word]**2 for word in tfidf1]))\n","    magnitude2 = math.sqrt(sum([tfidf2[word]**2 for word in tfidf2]))\n","\n","    # Calculate the cosine similarity\n","    similarity = dot_product / (magnitude1 * magnitude2)\n","    return similarity\n"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Image</th>\n","      <th>Review Text</th>\n","      <th>Image_Vectors</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3452</td>\n","      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n","      <td>love vintag spring vintag strat good tension g...</td>\n","      <td>[[[0.35204768, 0.53676, 0.49917382, 0.42068002...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1205</td>\n","      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n","      <td>work great guitar bench mat rug enough abus ta...</td>\n","      <td>[[[0.35107985, 0.5320194, 0.4778194, 0.4419130...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1708</td>\n","      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n","      <td>use everyth acoust bass ukulel know smaller mo...</td>\n","      <td>[[[0.38004225, 0.5307589, 0.4896015, 0.4049801...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2078</td>\n","      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n","      <td>great price good qualiti didnt quit match radi...</td>\n","      <td>[[[0.34581208, 0.55054736, 0.5456345, 0.385915...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>801</td>\n","      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n","      <td>bought bass split time primari bass dean edg m...</td>\n","      <td>[[[0.3345537, 0.50541735, 0.48309487, 0.465147...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                                              Image  \\\n","0        3452  [https://images-na.ssl-images-amazon.com/image...   \n","1        1205  [https://images-na.ssl-images-amazon.com/image...   \n","2        1708  [https://images-na.ssl-images-amazon.com/image...   \n","3        2078  [https://images-na.ssl-images-amazon.com/image...   \n","4         801  [https://images-na.ssl-images-amazon.com/image...   \n","\n","                                         Review Text  \\\n","0  love vintag spring vintag strat good tension g...   \n","1  work great guitar bench mat rug enough abus ta...   \n","2  use everyth acoust bass ukulel know smaller mo...   \n","3  great price good qualiti didnt quit match radi...   \n","4  bought bass split time primari bass dean edg m...   \n","\n","                                       Image_Vectors  \n","0  [[[0.35204768, 0.53676, 0.49917382, 0.42068002...  \n","1  [[[0.35107985, 0.5320194, 0.4778194, 0.4419130...  \n","2  [[[0.38004225, 0.5307589, 0.4896015, 0.4049801...  \n","3  [[[0.34581208, 0.55054736, 0.5456345, 0.385915...  \n","4  [[[0.3345537, 0.50541735, 0.48309487, 0.465147...  "]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>love</th>\n","      <th>vintag</th>\n","      <th>spring</th>\n","      <th>strat</th>\n","      <th>good</th>\n","      <th>tension</th>\n","      <th>great</th>\n","      <th>stabil</th>\n","      <th>float</th>\n","      <th>bridg</th>\n","      <th>...</th>\n","      <th>mayer</th>\n","      <th>importantli</th>\n","      <th>toneprint</th>\n","      <th>stringthru</th>\n","      <th>stopflair</th>\n","      <th>biggi</th>\n","      <th>accord</th>\n","      <th>screenshot</th>\n","      <th>amazoncom</th>\n","      <th>piti</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.060206</td>\n","      <td>0.23263</td>\n","      <td>0.28732</td>\n","      <td>0.091102</td>\n","      <td>0.045883</td>\n","      <td>0.139794</td>\n","      <td>0.032990</td>\n","      <td>0.139794</td>\n","      <td>0.168192</td>\n","      <td>0.097901</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.029924</td>\n","      <td>0.000000</td>\n","      <td>0.021515</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.057354</td>\n","      <td>0.000000</td>\n","      <td>0.041238</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.010758</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 5103 columns</p>\n","</div>"],"text/plain":["       love   vintag   spring     strat      good   tension     great  \\\n","0  0.060206  0.23263  0.28732  0.091102  0.045883  0.139794  0.032990   \n","1  0.000000  0.00000  0.00000  0.000000  0.029924  0.000000  0.021515   \n","2  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  0.000000   \n","3  0.000000  0.00000  0.00000  0.000000  0.057354  0.000000  0.041238   \n","4  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  0.010758   \n","\n","     stabil     float     bridg  ...  mayer  importantli  toneprint  \\\n","0  0.139794  0.168192  0.097901  ...    0.0          0.0        0.0   \n","1  0.000000  0.000000  0.000000  ...    0.0          0.0        0.0   \n","2  0.000000  0.000000  0.000000  ...    0.0          0.0        0.0   \n","3  0.000000  0.000000  0.000000  ...    0.0          0.0        0.0   \n","4  0.000000  0.000000  0.000000  ...    0.0          0.0        0.0   \n","\n","   stringthru  stopflair  biggi  accord  screenshot  amazoncom  piti  \n","0         0.0        0.0    0.0     0.0         0.0        0.0   0.0  \n","1         0.0        0.0    0.0     0.0         0.0        0.0   0.0  \n","2         0.0        0.0    0.0     0.0         0.0        0.0   0.0  \n","3         0.0        0.0    0.0     0.0         0.0        0.0   0.0  \n","4         0.0        0.0    0.0     0.0         0.0        0.0   0.0  \n","\n","[5 rows x 5103 columns]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["tfidf_df.head()"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["def cosine_similarityTF(dic1, dict2):\n","    # Calculate the dot product\n","    dot_product = sum([dic1[word] * dict2[word] for word in dic1 if word in dict2])\n","\n","    # Calculate the magnitude of the vectors\n","    magnitude1 = math.sqrt(sum([dic1[word]**2 for word in dic1]))\n","    magnitude2 = math.sqrt(sum([dict2[word]**2 for word in dict2]))\n","\n","    # Calculate the cosine similarity\n","    similarity = dot_product / (magnitude1 * magnitude2)\n","    return similarity"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["use everyth acoust bass ukulel\n","\n","similarities::::\n","0      0.000000\n","1      0.000000\n","2      0.222974\n","3      0.000000\n","4      0.197021\n","         ...   \n","995    0.000000\n","996    0.000000\n","997    0.005887\n","998    0.007303\n","999    0.016769\n","Length: 1000, dtype: float64\n","[(521, 0.3185190433750043), (526, 0.2993913054993825), (137, 0.2543392547953803), (786, 0.24498054996443322), (202, 0.23351073775895737), (692, 0.23156980046764178), (432, 0.2272936154387274), (402, 0.22441371076023228), (2, 0.22297415582961394), (278, 0.21128074922138768), (888, 0.20042539343924787), (4, 0.19702084172731324), (427, 0.1968077567307111), (895, 0.18913971903569707), (564, 0.18145407707781214), (119, 0.16855693162476237), (648, 0.1665986027671351), (926, 0.16588934817498058), (793, 0.16301166734067887), (769, 0.15973828593872755), (59, 0.1557478087432324), (149, 0.15317247429228528), (660, 0.15129771567363617), (288, 0.14855286735679182), (147, 0.14786654728578533), (457, 0.1461560544498011), (464, 0.1461302729741693), (703, 0.1444149315173595), (728, 0.1438287081245223), (620, 0.14091750552747428), (173, 0.13891778875474897), (688, 0.13714512183691785), (775, 0.1342040244811675), (444, 0.1340755911157565), (56, 0.1323582840408577), (107, 0.1274070242461786), (182, 0.12203405097941786), (906, 0.12024104875443034), (936, 0.11957598420551772), (47, 0.11881459695914252), (405, 0.11860460821560205), (915, 0.11369350404630266), (42, 0.11359823787863071), (247, 0.11338023511564489), (61, 0.11299961509864472), (749, 0.11278430134050647), (629, 0.11270144180981413), (821, 0.11140318245317006), (885, 0.11086426259784365), (732, 0.10993893670077581), (748, 0.10986802443578943), (463, 0.10754376950891555), (867, 0.10584519573174818), (287, 0.10583641496586242), (349, 0.09685678466707931), (823, 0.09569831418652112), (380, 0.09133809618672308), (164, 0.09018101679141072), (396, 0.0896645323757102), (20, 0.08927242342633011), (830, 0.08902155575303597), (441, 0.08773939719607504), (822, 0.08764179324141524), (279, 0.08638131658204294), (197, 0.08637177135593047), (185, 0.08571774505666607), (381, 0.0854935439690813), (496, 0.08512990945352712), (116, 0.083625890763223), (568, 0.08347850860597655), (613, 0.08301640439211738), (719, 0.08164595567151942), (234, 0.08126112488081184), (114, 0.08035832649505473), (519, 0.07899185457683548), (292, 0.07856214612356163), (86, 0.0783131129051747), (694, 0.07799996739723229), (156, 0.07765274989327502), (943, 0.07562286532703467), (973, 0.07311563797959986), (123, 0.07298969119461625), (595, 0.07228943259887406), (178, 0.07165764246991517), (729, 0.06826682426613241), (301, 0.06799041805926928), (602, 0.06789751488316535), (357, 0.06724289399509137), (696, 0.06668596029081987), (7, 0.06554452751228428), (743, 0.06502803599433717), (29, 0.06470844256461487), (665, 0.06274869938580976), (443, 0.062409567439610694), (894, 0.061896383696044804), (300, 0.061099329489715394), (22, 0.05985374175499449), (369, 0.05830512555777632), (433, 0.05811292994810272), (110, 0.05774915271645377), (183, 0.05676365611392691), (518, 0.05670173637040806), (190, 0.05503090639925832), (422, 0.05498640133185195), (387, 0.05432985184889882), (386, 0.05372292851469534), (41, 0.052204798363551456), (58, 0.052122386239460604), (452, 0.051779304107512934), (857, 0.05152598501657956), (745, 0.050192976777872406), (383, 0.04990836123878153), (707, 0.04983444695330965), (577, 0.048495626299704185), (259, 0.048154809771934974), (407, 0.0477832386179), (266, 0.04767905801232779), (122, 0.046620277801308285), (542, 0.046069966713321), (413, 0.046014940151013664), (489, 0.04579440661085782), (98, 0.045563833615970814), (572, 0.045283189980915094), (229, 0.045277880790455825), (269, 0.04509159858752113), (858, 0.04457220551211511), (36, 0.04452507857592899), (54, 0.04444559900770525), (322, 0.04431902960231477), (834, 0.043905242437740806), (264, 0.04338487040501945), (838, 0.042900861067222934), (193, 0.04223693171806513), (162, 0.04141730904070265), (50, 0.03979458818021068), (543, 0.038793095240829266), (158, 0.03874878478253377), (942, 0.03832155020560201), (346, 0.03705399433673788), (248, 0.03698124651076152), (255, 0.03693365032646297), (800, 0.03667776138986081), (406, 0.036242090915230195), (341, 0.035450399799515066), (812, 0.0352793558251751), (747, 0.03454270568039328), (372, 0.03414708739779929), (680, 0.033918445942322656), (637, 0.032118252857352196), (635, 0.030480041267618132), (820, 0.02985907742030622), (549, 0.029134485360389085), (803, 0.02885224500722051), (125, 0.027004544385275497), (626, 0.02683428535023699), (864, 0.026441246034625263), (19, 0.025184107337346037), (70, 0.02421536314132237), (850, 0.02312212122807624), (533, 0.022981426754983256), (590, 0.022973379721285186), (168, 0.022957329752824055), (941, 0.02263303722466439), (683, 0.022353808456223954), (199, 0.021920590015685703), (881, 0.02186563742681009), (265, 0.02102130183886166), (630, 0.02048284911931644), (733, 0.02022697344571985), (884, 0.020160551429383496), (172, 0.01978437336260747), (434, 0.01966232928603842), (919, 0.019358974797681856), (539, 0.018952000287701026), (531, 0.018859946056166314), (601, 0.01879612631470762), (467, 0.018609849639719116), (993, 0.01853237978057169), (664, 0.018401590146372573), (871, 0.018381278253514453), (388, 0.018351760834065145), (243, 0.018065481262519247), (484, 0.018000576705324244), (203, 0.017780961037766416), (468, 0.0176518901151671), (403, 0.01748940279269303), (556, 0.017421776531949422), (10, 0.017355284761633654), (948, 0.01734392349183315), (971, 0.017330452706790234), (836, 0.017117708797829426), (375, 0.01690158050826935), (145, 0.016827870357563834), (550, 0.016819025502991074), (916, 0.016769226797976843), (999, 0.016769226797976843), (937, 0.016576401183657365), (807, 0.016404551843902025), (100, 0.016400373033960938), (228, 0.016391304818869478), (710, 0.016388813837991543), (330, 0.016205652283397688), (87, 0.016169955549077804), (236, 0.01612405742243807), (494, 0.01612405742243807), (307, 0.015824521852017704), (827, 0.01532336182693234), (897, 0.015247458862979001), (497, 0.015231267491595306), (417, 0.015171366898299137), (927, 0.014934212453081701), (353, 0.014662936182430558), (515, 0.01464751867225446), (658, 0.014621172404629268), (846, 0.014469624363608451), (230, 0.014405286056072096), (874, 0.014007254987122393), (395, 0.013865599027419252), (475, 0.013203108813662249), (563, 0.012956387883299838), (421, 0.012925759241468814), (873, 0.012912238192475238), (226, 0.012590593111108116), (275, 0.012495745460857246), (220, 0.012400092245082426), (758, 0.012387849273299513), (474, 0.012363626094900002), (847, 0.012005554358060711), (809, 0.011934022060368773), (699, 0.011879263848758941), (242, 0.011842279358479564), (870, 0.011759394384983121), (115, 0.011677260832291259), (792, 0.011523919501445927), (954, 0.01145835804573663), (262, 0.011327535082787837), (414, 0.011248231660439659), (986, 0.011052727760052648), (456, 0.01093198658489477), (239, 0.010755367357064685), (840, 0.010625118661027477), (204, 0.010589950357193647), (984, 0.010491442151168394), (51, 0.010418909466087152), (118, 0.010399256701489147), (506, 0.010270462174484398), (634, 0.010225515974286652), (442, 0.010204988711796899), (89, 0.010185681271212294), (466, 0.010033645595297696), (612, 0.009884722993815898), (298, 0.009853901726356048), (883, 0.009753287691715939), (169, 0.009660729676255446), (326, 0.009536824047894547), (773, 0.009487530716951183), (191, 0.009438231226561662), (929, 0.009415766725270497), (557, 0.00932862894047549), (55, 0.009306370940542688), (257, 0.009191171731946028), (135, 0.009115961963892768), (651, 0.008994811122487125), (649, 0.008988663602371752), (529, 0.008949780415487583), (785, 0.008892676157024623), (250, 0.008859276396716985), (662, 0.008856150135260425), (224, 0.00885326007824136), (917, 0.008738000005847272), (491, 0.008729398169599074), (706, 0.008723397858831663), (788, 0.008676338469708647), (940, 0.00856969339873028), (121, 0.008463042198315176), (945, 0.008373888941668644), (532, 0.008332734186595447), (21, 0.008268445031039956), (714, 0.008231024371855513), (212, 0.008178755770266468), (646, 0.008155474304142716), (848, 0.008023413052636963), (453, 0.008006205243441637), (501, 0.008002457441403751), (702, 0.007970924975050054), (324, 0.007935188853793037), (181, 0.007921228147947284), (676, 0.007900142478842593), (385, 0.007849666638730657), (343, 0.007794790402064565), (143, 0.007754859288620739), (78, 0.007729418431495519), (232, 0.007724423751374617), (555, 0.007704707261178632), (509, 0.007673345034616302), (903, 0.007670309478266227), (619, 0.007591857293542737), (879, 0.007560487050925095), (332, 0.00750157778594636), (570, 0.007474325173490269), (302, 0.007470583894357773), (366, 0.0074334950353960845), (354, 0.007420394488341594), (439, 0.007376833052494592), (998, 0.007303408221776578), (921, 0.007167617635924385), (925, 0.007122559217152275), (985, 0.007119639207279423), (624, 0.0071077614362037266), (291, 0.007092896067846043), (958, 0.007026119901675811), (718, 0.006985680624359644), (336, 0.0069572881955161404), (251, 0.0069139748076032645), (738, 0.006904690043662159), (245, 0.006895687078354074), (946, 0.006850511716359068), (240, 0.0067982863915542115), (974, 0.0067601050659150935), (843, 0.006631936927317102), (176, 0.0065935215761790695), (13, 0.006544989373548916), (744, 0.006513611422319143), (653, 0.006491803297477914), (129, 0.006429451993480196), (961, 0.006370615112942983), (411, 0.006351993034711087), (546, 0.00634403989922213), (862, 0.0063403212035007565), (32, 0.0062715969454049765), (348, 0.006215896305632078), (691, 0.0062112821294364445), (677, 0.006181393103645061), (500, 0.006152197408974924), (200, 0.006081960941583692), (516, 0.00606938861156931), (424, 0.005975067034669313), (631, 0.005971206129365294), (905, 0.005921923637055219), (997, 0.005886768823698808), (101, 0.005885744524048284), (968, 0.005859166195864311), (327, 0.005845656762072853), (285, 0.005827184995122655), (735, 0.005810334050008923), (979, 0.005807327654601481), (765, 0.005771944471338802), (774, 0.005744603103246825), (437, 0.005736103597331939), (60, 0.005718023432558095), (268, 0.00570144188511546), (814, 0.005652825723944311), (639, 0.0056343819207457495), (195, 0.0056005760266638095), (608, 0.00558970000004713), (102, 0.005563850025753325), (768, 0.0055594008220215246), (72, 0.005535982043293355), (351, 0.005514071455823666), (219, 0.0054738983160359), (538, 0.0054189989601831565), (755, 0.005195850550995814), (889, 0.005171106926202166), (117, 0.005086278737562487), (88, 0.005076639983084709), (460, 0.005074929931208408), (628, 0.005070800129567267), (256, 0.005048863603918355), (804, 0.004992957047468217), (447, 0.0049548737045278166), (104, 0.004942101075225123), (541, 0.004932572502869097), (440, 0.004931557898861513), (522, 0.004817412001699676), (935, 0.004815795803261512), (878, 0.004812228994370462), (909, 0.004811512964829022), (210, 0.00479834147724441), (952, 0.004772516613631523), (636, 0.004747747836071015), (155, 0.004738121086350604), (18, 0.004709555080583491), (211, 0.004671062652573288), (994, 0.004622274751722529), (689, 0.004574865652149893), (27, 0.004574734326709235), (610, 0.004541431632552963), (944, 0.004479328553352232), (566, 0.0044680711031508695), (69, 0.004463026444969417), (730, 0.004451563892645685), (759, 0.0044343903990927795), (342, 0.004394427839731018), (490, 0.004375727792233177), (510, 0.004312400155445055), (17, 0.004278068692788194), (28, 0.004276711270211228), (304, 0.004247901145203006), (558, 0.004199010914021978), (227, 0.004146130382997183), (678, 0.004128756002892803), (399, 0.004113105281425659), (128, 0.004099819861202144), (64, 0.004087053811198463), (764, 0.0039927857324750125), (520, 0.0038706478492873454), (194, 0.003836984979941), (34, 0.003784261786607893), (717, 0.0037589945858855296), (63, 0.0036822437064966238), (715, 0.0036402687863106254), (221, 0.0035029963722841987), (325, 0.0034018953923789525), (412, 0.0032486333128240417), (293, 0.003238891000088143), (338, 0.0031585976997549423), (982, 0.003112900670237572), (106, 0.0028463214369465924), (523, 0.002524238498945474), (0, 0.0), (1, 0.0), (3, 0.0), (5, 0.0), (6, 0.0), (8, 0.0), (9, 0.0), (11, 0.0), (12, 0.0), (14, 0.0), (15, 0.0), (16, 0.0), (23, 0.0), (24, 0.0), (25, 0.0), (26, 0.0), (30, 0.0), (31, 0.0), (33, 0.0), (35, 0.0), (37, 0.0), (38, 0.0), (39, 0.0), (40, 0.0), (43, 0.0), (44, 0.0), (45, 0.0), (46, 0.0), (48, 0.0), (49, 0.0), (52, 0.0), (53, 0.0), (57, 0.0), (62, 0.0), (65, 0.0), (66, 0.0), (67, 0.0), (68, 0.0), (71, 0.0), (73, 0.0), (74, 0.0), (75, 0.0), (76, 0.0), (77, 0.0), (79, 0.0), (80, 0.0), (81, 0.0), (82, 0.0), (83, 0.0), (84, 0.0), (85, 0.0), (90, 0.0), (91, 0.0), (92, 0.0), (93, 0.0), (94, 0.0), (95, 0.0), (96, 0.0), (97, 0.0), (99, 0.0), (103, 0.0), (105, 0.0), (108, 0.0), (109, 0.0), (111, 0.0), (112, 0.0), (113, 0.0), (120, 0.0), (124, 0.0), (126, 0.0), (127, 0.0), (130, 0.0), (131, 0.0), (132, 0.0), (133, 0.0), (134, 0.0), (136, 0.0), (138, 0.0), (139, 0.0), (140, 0.0), (141, 0.0), (142, 0.0), (144, 0.0), (146, 0.0), (148, 0.0), (150, 0.0), (151, 0.0), (152, 0.0), (153, 0.0), (154, 0.0), (157, 0.0), (159, 0.0), (160, 0.0), (161, 0.0), (163, 0.0), (165, 0.0), (166, 0.0), (167, 0.0), (170, 0.0), (171, 0.0), (174, 0.0), (175, 0.0), (177, 0.0), (179, 0.0), (180, 0.0), (184, 0.0), (186, 0.0), (187, 0.0), (188, 0.0), (189, 0.0), (192, 0.0), (196, 0.0), (198, 0.0), (201, 0.0), (205, 0.0), (206, 0.0), (207, 0.0), (208, 0.0), (209, 0.0), (213, 0.0), (214, 0.0), (215, 0.0), (216, 0.0), (217, 0.0), (218, 0.0), (222, 0.0), (223, 0.0), (225, 0.0), (231, 0.0), (233, 0.0), (235, 0.0), (237, 0.0), (238, 0.0), (241, 0.0), (244, 0.0), (246, 0.0), (249, 0.0), (252, 0.0), (253, 0.0), (254, 0.0), (258, 0.0), (260, 0.0), (261, 0.0), (263, 0.0), (267, 0.0), (270, 0.0), (271, 0.0), (272, 0.0), (273, 0.0), (274, 0.0), (276, 0.0), (277, 0.0), (280, 0.0), (281, 0.0), (282, 0.0), (283, 0.0), (284, 0.0), (286, 0.0), (289, 0.0), (290, 0.0), (294, 0.0), (295, 0.0), (296, 0.0), (297, 0.0), (299, 0.0), (303, 0.0), (305, 0.0), (306, 0.0), (308, 0.0), (309, 0.0), (310, 0.0), (311, 0.0), (312, 0.0), (313, 0.0), (314, 0.0), (315, 0.0), (316, 0.0), (317, 0.0), (318, 0.0), (319, 0.0), (320, 0.0), (321, 0.0), (323, 0.0), (328, 0.0), (329, 0.0), (331, 0.0), (333, 0.0), (334, 0.0), (335, 0.0), (337, 0.0), (339, 0.0), (340, 0.0), (344, 0.0), (345, 0.0), (347, 0.0), (350, 0.0), (352, 0.0), (355, 0.0), (356, 0.0), (358, 0.0), (359, 0.0), (360, 0.0), (361, 0.0), (362, 0.0), (363, 0.0), (364, 0.0), (365, 0.0), (367, 0.0), (368, 0.0), (370, 0.0), (371, 0.0), (373, 0.0), (374, 0.0), (376, 0.0), (377, 0.0), (378, 0.0), (379, 0.0), (382, 0.0), (384, 0.0), (389, 0.0), (390, 0.0), (391, 0.0), (392, 0.0), (393, 0.0), (394, 0.0), (397, 0.0), (398, 0.0), (400, 0.0), (401, 0.0), (404, 0.0), (408, 0.0), (409, 0.0), (410, 0.0), (415, 0.0), (416, 0.0), (418, 0.0), (419, 0.0), (420, 0.0), (423, 0.0), (425, 0.0), (426, 0.0), (428, 0.0), (429, 0.0), (430, 0.0), (431, 0.0), (435, 0.0), (436, 0.0), (438, 0.0), (445, 0.0), (446, 0.0), (448, 0.0), (449, 0.0), (450, 0.0), (451, 0.0), (454, 0.0), (455, 0.0), (458, 0.0), (459, 0.0), (461, 0.0), (462, 0.0), (465, 0.0), (469, 0.0), (470, 0.0), (471, 0.0), (472, 0.0), (473, 0.0), (476, 0.0), (477, 0.0), (478, 0.0), (479, 0.0), (480, 0.0), (481, 0.0), (482, 0.0), (483, 0.0), (485, 0.0), (486, 0.0), (487, 0.0), (488, 0.0), (492, 0.0), (493, 0.0), (495, 0.0), (498, 0.0), (499, 0.0), (502, 0.0), (503, 0.0), (504, 0.0), (505, 0.0), (507, 0.0), (508, 0.0), (511, 0.0), (512, 0.0), (513, 0.0), (514, 0.0), (517, 0.0), (524, 0.0), (525, 0.0), (527, 0.0), (528, 0.0), (530, 0.0), (534, 0.0), (535, 0.0), (536, 0.0), (537, 0.0), (540, 0.0), (544, 0.0), (545, 0.0), (547, 0.0), (548, 0.0), (551, 0.0), (552, 0.0), (553, 0.0), (554, 0.0), (559, 0.0), (560, 0.0), (561, 0.0), (562, 0.0), (565, 0.0), (567, 0.0), (569, 0.0), (571, 0.0), (573, 0.0), (574, 0.0), (575, 0.0), (576, 0.0), (578, 0.0), (579, 0.0), (580, 0.0), (581, 0.0), (582, 0.0), (583, 0.0), (584, 0.0), (585, 0.0), (586, 0.0), (587, 0.0), (588, 0.0), (589, 0.0), (591, 0.0), (592, 0.0), (593, 0.0), (594, 0.0), (596, 0.0), (597, 0.0), (598, 0.0), (599, 0.0), (600, 0.0), (603, 0.0), (604, 0.0), (605, 0.0), (606, 0.0), (607, 0.0), (609, 0.0), (611, 0.0), (614, 0.0), (615, 0.0), (616, 0.0), (617, 0.0), (618, 0.0), (621, 0.0), (622, 0.0), (623, 0.0), (625, 0.0), (627, 0.0), (632, 0.0), (633, 0.0), (638, 0.0), (640, 0.0), (641, 0.0), (642, 0.0), (643, 0.0), (644, 0.0), (645, 0.0), (647, 0.0), (650, 0.0), (652, 0.0), (654, 0.0), (655, 0.0), (656, 0.0), (657, 0.0), (659, 0.0), (661, 0.0), (663, 0.0), (666, 0.0), (667, 0.0), (668, 0.0), (669, 0.0), (670, 0.0), (671, 0.0), (672, 0.0), (673, 0.0), (674, 0.0), (675, 0.0), (679, 0.0), (681, 0.0), (682, 0.0), (684, 0.0), (685, 0.0), (686, 0.0), (687, 0.0), (690, 0.0), (693, 0.0), (695, 0.0), (697, 0.0), (698, 0.0), (700, 0.0), (701, 0.0), (704, 0.0), (705, 0.0), (708, 0.0), (709, 0.0), (711, 0.0), (712, 0.0), (713, 0.0), (716, 0.0), (720, 0.0), (721, 0.0), (722, 0.0), (723, 0.0), (724, 0.0), (725, 0.0), (726, 0.0), (727, 0.0), (731, 0.0), (734, 0.0), (736, 0.0), (737, 0.0), (739, 0.0), (740, 0.0), (741, 0.0), (742, 0.0), (746, 0.0), (750, 0.0), (751, 0.0), (752, 0.0), (753, 0.0), (754, 0.0), (756, 0.0), (757, 0.0), (760, 0.0), (761, 0.0), (762, 0.0), (763, 0.0), (766, 0.0), (767, 0.0), (770, 0.0), (771, 0.0), (772, 0.0), (776, 0.0), (777, 0.0), (778, 0.0), (779, 0.0), (780, 0.0), (781, 0.0), (782, 0.0), (783, 0.0), (784, 0.0), (787, 0.0), (789, 0.0), (790, 0.0), (791, 0.0), (794, 0.0), (795, 0.0), (796, 0.0), (797, 0.0), (798, 0.0), (799, 0.0), (801, 0.0), (802, 0.0), (805, 0.0), (806, 0.0), (808, 0.0), (810, 0.0), (811, 0.0), (813, 0.0), (815, 0.0), (816, 0.0), (817, 0.0), (818, 0.0), (819, 0.0), (824, 0.0), (825, 0.0), (826, 0.0), (828, 0.0), (829, 0.0), (831, 0.0), (832, 0.0), (833, 0.0), (835, 0.0), (837, 0.0), (839, 0.0), (841, 0.0), (842, 0.0), (844, 0.0), (845, 0.0), (849, 0.0), (851, 0.0), (852, 0.0), (853, 0.0), (854, 0.0), (855, 0.0), (856, 0.0), (859, 0.0), (860, 0.0), (861, 0.0), (863, 0.0), (865, 0.0), (866, 0.0), (868, 0.0), (869, 0.0), (872, 0.0), (875, 0.0), (876, 0.0), (877, 0.0), (880, 0.0), (882, 0.0), (886, 0.0), (887, 0.0), (890, 0.0), (891, 0.0), (892, 0.0), (893, 0.0), (896, 0.0), (898, 0.0), (899, 0.0), (900, 0.0), (901, 0.0), (902, 0.0), (904, 0.0), (907, 0.0), (908, 0.0), (910, 0.0), (911, 0.0), (912, 0.0), (913, 0.0), (914, 0.0), (918, 0.0), (920, 0.0), (922, 0.0), (923, 0.0), (924, 0.0), (928, 0.0), (930, 0.0), (931, 0.0), (932, 0.0), (933, 0.0), (934, 0.0), (938, 0.0), (939, 0.0), (947, 0.0), (949, 0.0), (950, 0.0), (951, 0.0), (953, 0.0), (955, 0.0), (956, 0.0), (957, 0.0), (959, 0.0), (960, 0.0), (962, 0.0), (963, 0.0), (964, 0.0), (965, 0.0), (966, 0.0), (967, 0.0), (969, 0.0), (970, 0.0), (972, 0.0), (975, 0.0), (976, 0.0), (977, 0.0), (978, 0.0), (980, 0.0), (981, 0.0), (983, 0.0), (987, 0.0), (988, 0.0), (989, 0.0), (990, 0.0), (991, 0.0), (992, 0.0), (995, 0.0), (996, 0.0)]\n"]},{"ename":"IndexError","evalue":"positional indexers are out-of-bounds","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexing.py:1715\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1714\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1715\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1716\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1717\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:4147\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   4138\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4139\u001b[0m \u001b[38;5;124;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   4140\u001b[0m \u001b[38;5;124;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4145\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   4146\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4147\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4148\u001b[0m \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:4127\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4123\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   4124\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[0;32m   4125\u001b[0m     )\n\u001b[1;32m-> 4127\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4129\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4133\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4134\u001b[0m )\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:892\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    891\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[1;32m--> 892\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexers\\utils.py:282\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[1;34m(indices, n, verify)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n","\u001b[1;31mIndexError\u001b[0m: indices are out-of-bounds","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[60], line 40\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#  find the most similar reviews to the query text\u001b[39;00m\n\u001b[0;32m     37\u001b[0m query_text \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124muse everyth acoust bass ukulel rando wantd\u001b[39m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 40\u001b[0m most_similar \u001b[38;5;241m=\u001b[39m \u001b[43mmost_similar_reviews\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_text\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[60], line 30\u001b[0m, in \u001b[0;36mmost_similar_reviews\u001b[1;34m(query_text)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(similars)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#  return the most similar reviews\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m most_similar \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msimilars\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m most_similar\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexing.py:1192\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1191\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexing.py:1744\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[1;32m-> 1744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1748\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexing.py:1718\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1715\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1716\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1717\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[1;32m-> 1718\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n","\u001b[1;31mIndexError\u001b[0m: positional indexers are out-of-bounds"]}],"source":["def most_similar_reviews(query_text):\n","    # Preprocess the query text\n","    preprocessed_query = preprocess_review_text(query_text)\n","\n","    #  drop all the words from preprocessed_query that are not in the tfidf_df\n","    preprocessed_query = ' '.join([word for word in preprocessed_query.split() if word in tfidf_df.columns])\n","\n","    # convert the query text to a tfidf vector\n","    query_tfidf = calculate_tfidf(preprocessed_query, calculate_idf(data['Review Text']))\n","\n","    print(preprocessed_query)\n","    # find and print cosine similarity between the query text and 1st review\n","    #  retrieve tfidf_df.iloc[0] adn change it into  a dictionary\n","    tfidf_dict = tfidf_df.iloc[0].to_dict()\n","\n","    similarity = cosine_similarityTF(tfidf_dict, query_tfidf)\n","    print()\n","\n","    # find and print cosine similarity between the query text and all reviews and rank them\n","    similarities = tfidf_df.apply(lambda row: cosine_similarityTF(row.to_dict(), query_tfidf), axis=1)\n","    print(\"similarities::::\")\n","    print(similarities)\n","    #  use similarity to rank reviews in descending order\n","    similars=[]\n","    for i in range(len(similarities)):\n","        similars.append((i, similarities[i]))\n","    similars.sort(key=lambda x: x[1], reverse=True)\n","    print(similars)\n","    #  return the most similar reviews\n","    most_similar = data.iloc[[x[0] for x in similars]]\n","\n","\n","    return most_similar\n","\n","\n","#  find the most similar reviews to the query text\n","query_text =\"\"\"\n","use everyth acoust bass ukulel rando wantd\n","\"\"\"\n","most_similar = most_similar_reviews(query_text)\n","\n"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Image</th>\n","      <th>Review Text</th>\n","      <th>Image_Vectors</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3452</td>\n","      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n","      <td>love vintag spring vintag strat good tension g...</td>\n","      <td>[[[0.35204768, 0.53676, 0.49917382, 0.42068002...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1205</td>\n","      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n","      <td>work great guitar bench mat rug enough abus ta...</td>\n","      <td>[[[0.35107985, 0.5320194, 0.4778194, 0.4419130...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1708</td>\n","      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n","      <td>use everyth acoust bass ukulel know smaller mo...</td>\n","      <td>[[[0.38004225, 0.5307589, 0.4896015, 0.4049801...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2078</td>\n","      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n","      <td>great price good qualiti didnt quit match radi...</td>\n","      <td>[[[0.34581208, 0.55054736, 0.5456345, 0.385915...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>801</td>\n","      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n","      <td>bought bass split time primari bass dean edg m...</td>\n","      <td>[[[0.3345537, 0.50541735, 0.48309487, 0.465147...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                                              Image  \\\n","0        3452  [https://images-na.ssl-images-amazon.com/image...   \n","1        1205  [https://images-na.ssl-images-amazon.com/image...   \n","2        1708  [https://images-na.ssl-images-amazon.com/image...   \n","3        2078  [https://images-na.ssl-images-amazon.com/image...   \n","4         801  [https://images-na.ssl-images-amazon.com/image...   \n","\n","                                         Review Text  \\\n","0  love vintag spring vintag strat good tension g...   \n","1  work great guitar bench mat rug enough abus ta...   \n","2  use everyth acoust bass ukulel know smaller mo...   \n","3  great price good qualiti didnt quit match radi...   \n","4  bought bass split time primari bass dean edg m...   \n","\n","                                       Image_Vectors  \n","0  [[[0.35204768, 0.53676, 0.49917382, 0.42068002...  \n","1  [[[0.35107985, 0.5320194, 0.4778194, 0.4419130...  \n","2  [[[0.38004225, 0.5307589, 0.4896015, 0.4049801...  \n","3  [[[0.34581208, 0.55054736, 0.5456345, 0.385915...  \n","4  [[[0.3345537, 0.50541735, 0.48309487, 0.465147...  "]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4590677,"sourceId":7832681,"sourceType":"datasetVersion"},{"datasetId":4592011,"sourceId":7834440,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
